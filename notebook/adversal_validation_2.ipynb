{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit9025878f636247c5ae672c7e619bf82e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "import random\n",
    "from collections import Counter, defaultdict"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 1
  },
  {
   "source": [
    "def stratified_group_k_fold(X, y, groups, k, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    # ラベルの数をカウント\n",
    "    labels_num = np.max(y) + 1\n",
    "    # 各グループのラベルの数をカウントする\n",
    "    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "    y_distr = Counter()\n",
    "    for label, g in zip(y, groups):\n",
    "        y_counts_per_group[g][label] += 1\n",
    "        y_distr[label] += 1\n",
    "    # 各フォールドのラベルの数をカウント\n",
    "    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "    groups_per_fold = defaultdict(set)\n",
    "\n",
    "    def eval_y_counts_per_fold(y_counts, fold):\n",
    "        y_counts_per_fold[fold] += y_counts\n",
    "        std_per_label = []\n",
    "        for label in range(labels_num):\n",
    "            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
    "            std_per_label.append(label_std)\n",
    "        y_counts_per_fold[fold] -= y_counts\n",
    "        return np.mean(std_per_label)\n",
    "\n",
    "    groups_and_y_counts = list(y_counts_per_group.items())\n",
    "    random.Random(seed).shuffle(groups_and_y_counts)\n",
    "\n",
    "    for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for i in range(k):\n",
    "            fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "            if min_eval is None or fold_eval < min_eval:\n",
    "                min_eval = fold_eval\n",
    "                best_fold = i\n",
    "        y_counts_per_fold[best_fold] += y_counts\n",
    "        groups_per_fold[best_fold].add(g)\n",
    "\n",
    "    all_groups = set(groups)\n",
    "\n",
    "    for i in range(k):\n",
    "        test_k = i\n",
    "        # val_k = i+1 if i+1 != k else 0\n",
    "        # print(val_k)\n",
    "        train_groups = all_groups - groups_per_fold[test_k]  #  - groups_per_fold[val_k]\n",
    "        # val_groups = groups_per_fold[val_k]\n",
    "        test_groups = groups_per_fold[test_k]\n",
    "        # print(test_groups)\n",
    "        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "        # val_indices = [i for i, g in enumerate(groups) if g in val_groups]\n",
    "        # test_indices = {str(g): [i for i, g in enumerate(groups) if g in test_groups]}\n",
    "\n",
    "        test_indices = []\n",
    "        n_g = None\n",
    "        test_list = []\n",
    "        for i, g in enumerate(groups):\n",
    "            if g in test_groups:\n",
    "                if n_g is not None and n_g != g:\n",
    "                    test_indices.append(test_list)\n",
    "                    test_list = []\n",
    "                test_list.append(i)\n",
    "                n_g = g\n",
    "\n",
    "        test_indices = [np.random.choice(i) for i in test_indices]\n",
    "        yield train_indices, test_indices  # val_indices,"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 2
  },
  {
   "source": [
    "train_path = '/code/data/processed/proceeded_train_20200116_102618.csv'\n",
    "test_path = '/code/data/processed/proceeded_test_20200116_102618.csv'\n",
    "\n",
    "train = pd.read_csv(train_path, index_col=0)\n",
    "test = pd.read_csv(test_path, index_col=0)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 3
  },
  {
   "source": [
    "train.head()"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Clip  Activity  Assessment  Game  session_title  count_correct_attempts  \\\n0    11         3           0     4             42                       0   \n1    14         4           1     6             30                       1   \n2    14         4           2     6             42                       1   \n3    24         9           4    10             42                       2   \n4    28        10           5    13             30                       3   \n\n   count_uncorrect_attempts  count_accuracy  acc_Cart Balancer (Assessment)  \\\n0                         0             0.0                            -1.0   \n1                         0             1.0                            -1.0   \n2                        11             0.5                            -1.0   \n3                        11             0.5                            -1.0   \n4                        12             0.5                            -1.0   \n\n   acc_Cauldron Filler (Assessment)  ...  \\\n0                              -1.0  ...   \n1                              -1.0  ...   \n2                              -1.0  ...   \n3                              -1.0  ...   \n4                              -1.0  ...   \n\n   label_count_action_label_description_val  \\\n0                                        99   \n1                                       104   \n2                                       129   \n3                                       130   \n4                                       104   \n\n   count_label_count_action_label_description_val  \\\n0                                             337   \n1                                             488   \n2                                             290   \n3                                             522   \n4                                             488   \n\n   label_session_title_description_val  \\\n0                                  158   \n1                                   76   \n2                                  154   \n3                                  155   \n4                                   76   \n\n   count_label_session_title_description_val  \\\n0                                        763   \n1                                        959   \n2                                        370   \n3                                        534   \n4                                        959   \n\n   label_session_title_count_action_label  \\\n0                                      46   \n1                                      27   \n2                                      47   \n3                                      47   \n4                                      27   \n\n   count_label_session_title_count_action_label  \\\n0                                           747   \n1                                           814   \n2                                          1006   \n3                                          1006   \n4                                           814   \n\n   label_session_title_count_accuracy_label  \\\n0                                        20   \n1                                        14   \n2                                        22   \n3                                        22   \n4                                        12   \n\n   count_label_session_title_count_accuracy_label  \\\n0                                            1115   \n1                                             463   \n2                                            1192   \n3                                            1192   \n4                                            1012   \n\n   label_session_title_mean_accuracy_group_label  \\\n0                                             20   \n1                                             14   \n2                                             22   \n3                                             22   \n4                                             12   \n\n   count_label_session_title_mean_accuracy_group_label  \n0                                               1115    \n1                                                463    \n2                                               1036    \n3                                               1036    \n4                                                883    \n\n[5 rows x 701 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Clip</th>\n      <th>Activity</th>\n      <th>Assessment</th>\n      <th>Game</th>\n      <th>session_title</th>\n      <th>count_correct_attempts</th>\n      <th>count_uncorrect_attempts</th>\n      <th>count_accuracy</th>\n      <th>acc_Cart Balancer (Assessment)</th>\n      <th>acc_Cauldron Filler (Assessment)</th>\n      <th>...</th>\n      <th>label_count_action_label_description_val</th>\n      <th>count_label_count_action_label_description_val</th>\n      <th>label_session_title_description_val</th>\n      <th>count_label_session_title_description_val</th>\n      <th>label_session_title_count_action_label</th>\n      <th>count_label_session_title_count_action_label</th>\n      <th>label_session_title_count_accuracy_label</th>\n      <th>count_label_session_title_count_accuracy_label</th>\n      <th>label_session_title_mean_accuracy_group_label</th>\n      <th>count_label_session_title_mean_accuracy_group_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>99</td>\n      <td>337</td>\n      <td>158</td>\n      <td>763</td>\n      <td>46</td>\n      <td>747</td>\n      <td>20</td>\n      <td>1115</td>\n      <td>20</td>\n      <td>1115</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14</td>\n      <td>4</td>\n      <td>1</td>\n      <td>6</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>104</td>\n      <td>488</td>\n      <td>76</td>\n      <td>959</td>\n      <td>27</td>\n      <td>814</td>\n      <td>14</td>\n      <td>463</td>\n      <td>14</td>\n      <td>463</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>42</td>\n      <td>1</td>\n      <td>11</td>\n      <td>0.5</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>129</td>\n      <td>290</td>\n      <td>154</td>\n      <td>370</td>\n      <td>47</td>\n      <td>1006</td>\n      <td>22</td>\n      <td>1192</td>\n      <td>22</td>\n      <td>1036</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>24</td>\n      <td>9</td>\n      <td>4</td>\n      <td>10</td>\n      <td>42</td>\n      <td>2</td>\n      <td>11</td>\n      <td>0.5</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>130</td>\n      <td>522</td>\n      <td>155</td>\n      <td>534</td>\n      <td>47</td>\n      <td>1006</td>\n      <td>22</td>\n      <td>1192</td>\n      <td>22</td>\n      <td>1036</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>10</td>\n      <td>5</td>\n      <td>13</td>\n      <td>30</td>\n      <td>3</td>\n      <td>12</td>\n      <td>0.5</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>104</td>\n      <td>488</td>\n      <td>76</td>\n      <td>959</td>\n      <td>27</td>\n      <td>814</td>\n      <td>12</td>\n      <td>1012</td>\n      <td>12</td>\n      <td>883</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 701 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "source": [
    "train['target'] = 0\n",
    "test['target'] = 1"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 5
  },
  {
   "source": [
    "test['target']"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0      1\n1      1\n2      1\n3      1\n4      1\n      ..\n995    1\n996    1\n997    1\n998    1\n999    1\nName: target, Length: 1000, dtype: int64"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "source": [
    "train_df = pd.concat([train, test])\n",
    "train_df.columns = train_df.columns.str.replace(',', '')"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 7
  },
  {
   "source": [
    "train_df.shape"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(18690, 702)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "source": [
    "y = train_df['target']\n",
    "x = train_df.drop('target', axis=1)\n",
    "groups = np.array(x['installation_id'])\n",
    "lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "    }\n",
    "x = x.drop(['accuracy_group', 'installation_id'], axis=1)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 9
  },
  {
   "source": [
    "def lgb_regression(x, y, groups, lgb_params) -> pd.DataFrame:\n",
    "\n",
    "    num_fold = 3\n",
    "    pred = np.zeros(y.shape)\n",
    "    all_importance = []\n",
    "\n",
    "    for fold_ind, (train_ind, test_ind) in enumerate(\n",
    "            stratified_group_k_fold(X=x, y=y, groups=groups, k=num_fold, seed=77)):\n",
    "        x_train = x.iloc[train_ind]\n",
    "        y_train = y.iloc[train_ind]\n",
    "        x_test = x.iloc[test_ind]\n",
    "        y_test = y.iloc[test_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        lgb_val = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "\n",
    "        model = lgb.train(params=lgb_params,\n",
    "                          train_set=lgb_train,\n",
    "                          valid_sets=lgb_val)\n",
    "\n",
    "        pred[test_ind] = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "\n",
    "        all_importance.append(pd.DataFrame(model.feature_importance('gain'), index=x_train.columns))\n",
    "\n",
    "    all_importance = pd.concat(all_importance, axis=1)\n",
    "    return pred, all_importance\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 10
  },
  {
   "source": [
    "pred, importance = lgb_regression(x, y, groups, lgb_params)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1]\tvalid_0's auc: 0.530549\n[2]\tvalid_0's auc: 0.568\n[3]\tvalid_0's auc: 0.578914\n[4]\tvalid_0's auc: 0.584547\n[5]\tvalid_0's auc: 0.582844\n[6]\tvalid_0's auc: 0.582641\n[7]\tvalid_0's auc: 0.580566\n[8]\tvalid_0's auc: 0.581874\n[9]\tvalid_0's auc: 0.578889\n[10]\tvalid_0's auc: 0.573098\n[11]\tvalid_0's auc: 0.574261\n[12]\tvalid_0's auc: 0.576296\n[13]\tvalid_0's auc: 0.580833\n[14]\tvalid_0's auc: 0.580249\n[15]\tvalid_0's auc: 0.580892\n[16]\tvalid_0's auc: 0.581141\n[17]\tvalid_0's auc: 0.57895\n[18]\tvalid_0's auc: 0.577672\n[19]\tvalid_0's auc: 0.577922\n[20]\tvalid_0's auc: 0.578021\n[21]\tvalid_0's auc: 0.580347\n[22]\tvalid_0's auc: 0.585092\n[23]\tvalid_0's auc: 0.585072\n[24]\tvalid_0's auc: 0.588135\n[25]\tvalid_0's auc: 0.590367\n[26]\tvalid_0's auc: 0.591797\n[27]\tvalid_0's auc: 0.59528\n[28]\tvalid_0's auc: 0.596011\n[29]\tvalid_0's auc: 0.597525\n[30]\tvalid_0's auc: 0.598491\n[31]\tvalid_0's auc: 0.599039\n[32]\tvalid_0's auc: 0.600118\n[33]\tvalid_0's auc: 0.602339\n[34]\tvalid_0's auc: 0.601359\n[35]\tvalid_0's auc: 0.600436\n[36]\tvalid_0's auc: 0.599819\n[37]\tvalid_0's auc: 0.600142\n[38]\tvalid_0's auc: 0.601558\n[39]\tvalid_0's auc: 0.60312\n[40]\tvalid_0's auc: 0.605806\n[41]\tvalid_0's auc: 0.603446\n[42]\tvalid_0's auc: 0.602017\n[43]\tvalid_0's auc: 0.603294\n[44]\tvalid_0's auc: 0.603541\n[45]\tvalid_0's auc: 0.605356\n[46]\tvalid_0's auc: 0.60553\n[47]\tvalid_0's auc: 0.607256\n[48]\tvalid_0's auc: 0.608064\n[49]\tvalid_0's auc: 0.609878\n[50]\tvalid_0's auc: 0.610111\n[51]\tvalid_0's auc: 0.610807\n[52]\tvalid_0's auc: 0.611336\n[53]\tvalid_0's auc: 0.612261\n[54]\tvalid_0's auc: 0.614349\n[55]\tvalid_0's auc: 0.615431\n[56]\tvalid_0's auc: 0.615002\n[57]\tvalid_0's auc: 0.614231\n[58]\tvalid_0's auc: 0.614092\n[59]\tvalid_0's auc: 0.613164\n[60]\tvalid_0's auc: 0.614266\n[61]\tvalid_0's auc: 0.615556\n[62]\tvalid_0's auc: 0.616232\n[63]\tvalid_0's auc: 0.617047\n[64]\tvalid_0's auc: 0.617551\n[65]\tvalid_0's auc: 0.617489\n[66]\tvalid_0's auc: 0.616581\n[67]\tvalid_0's auc: 0.616096\n[68]\tvalid_0's auc: 0.616759\n[69]\tvalid_0's auc: 0.617278\n[70]\tvalid_0's auc: 0.617729\n[71]\tvalid_0's auc: 0.616588\n[72]\tvalid_0's auc: 0.615768\n[73]\tvalid_0's auc: 0.616391\n[74]\tvalid_0's auc: 0.616162\n[75]\tvalid_0's auc: 0.61477\n[76]\tvalid_0's auc: 0.615887\n[77]\tvalid_0's auc: 0.616401\n[78]\tvalid_0's auc: 0.617272\n[79]\tvalid_0's auc: 0.617037\n[80]\tvalid_0's auc: 0.617616\n[81]\tvalid_0's auc: 0.616972\n[82]\tvalid_0's auc: 0.617019\n[83]\tvalid_0's auc: 0.616605\n[84]\tvalid_0's auc: 0.616606\n[85]\tvalid_0's auc: 0.616721\n[86]\tvalid_0's auc: 0.617377\n[87]\tvalid_0's auc: 0.616843\n[88]\tvalid_0's auc: 0.616573\n[89]\tvalid_0's auc: 0.616192\n[90]\tvalid_0's auc: 0.616519\n[91]\tvalid_0's auc: 0.616541\n[92]\tvalid_0's auc: 0.616197\n[93]\tvalid_0's auc: 0.616099\n[94]\tvalid_0's auc: 0.615588\n[95]\tvalid_0's auc: 0.616626\n[96]\tvalid_0's auc: 0.616292\n[97]\tvalid_0's auc: 0.616344\n[98]\tvalid_0's auc: 0.615207\n[99]\tvalid_0's auc: 0.615084\n[100]\tvalid_0's auc: 0.614568\n[1]\tvalid_0's auc: 0.523893\n[2]\tvalid_0's auc: 0.541035\n[3]\tvalid_0's auc: 0.547593\n[4]\tvalid_0's auc: 0.545569\n[5]\tvalid_0's auc: 0.56475\n[6]\tvalid_0's auc: 0.566826\n[7]\tvalid_0's auc: 0.57403\n[8]\tvalid_0's auc: 0.575012\n[9]\tvalid_0's auc: 0.581244\n[10]\tvalid_0's auc: 0.58272\n[11]\tvalid_0's auc: 0.592066\n[12]\tvalid_0's auc: 0.590794\n[13]\tvalid_0's auc: 0.591894\n[14]\tvalid_0's auc: 0.588465\n[15]\tvalid_0's auc: 0.588659\n[16]\tvalid_0's auc: 0.592851\n[17]\tvalid_0's auc: 0.58998\n[18]\tvalid_0's auc: 0.58926\n[19]\tvalid_0's auc: 0.58945\n[20]\tvalid_0's auc: 0.587127\n[21]\tvalid_0's auc: 0.586694\n[22]\tvalid_0's auc: 0.585626\n[23]\tvalid_0's auc: 0.587102\n[24]\tvalid_0's auc: 0.587558\n[25]\tvalid_0's auc: 0.586427\n[26]\tvalid_0's auc: 0.585585\n[27]\tvalid_0's auc: 0.585586\n[28]\tvalid_0's auc: 0.585082\n[29]\tvalid_0's auc: 0.583747\n[30]\tvalid_0's auc: 0.58353\n[31]\tvalid_0's auc: 0.583352\n[32]\tvalid_0's auc: 0.584655\n[33]\tvalid_0's auc: 0.584671\n[34]\tvalid_0's auc: 0.582456\n[35]\tvalid_0's auc: 0.582601\n[36]\tvalid_0's auc: 0.582784\n[37]\tvalid_0's auc: 0.584091\n[38]\tvalid_0's auc: 0.584749\n[39]\tvalid_0's auc: 0.584471\n[40]\tvalid_0's auc: 0.584411\n[41]\tvalid_0's auc: 0.583531\n[42]\tvalid_0's auc: 0.583941\n[43]\tvalid_0's auc: 0.586185\n[44]\tvalid_0's auc: 0.586832\n[45]\tvalid_0's auc: 0.585722\n[46]\tvalid_0's auc: 0.587217\n[47]\tvalid_0's auc: 0.58594\n[48]\tvalid_0's auc: 0.58521\n[49]\tvalid_0's auc: 0.585362\n[50]\tvalid_0's auc: 0.586754\n[51]\tvalid_0's auc: 0.586087\n[52]\tvalid_0's auc: 0.588902\n[53]\tvalid_0's auc: 0.590876\n[54]\tvalid_0's auc: 0.592021\n[55]\tvalid_0's auc: 0.592154\n[56]\tvalid_0's auc: 0.592626\n[57]\tvalid_0's auc: 0.591219\n[58]\tvalid_0's auc: 0.591149\n[59]\tvalid_0's auc: 0.590924\n[60]\tvalid_0's auc: 0.590859\n[61]\tvalid_0's auc: 0.591556\n[62]\tvalid_0's auc: 0.591896\n[63]\tvalid_0's auc: 0.590629\n[64]\tvalid_0's auc: 0.590434\n[65]\tvalid_0's auc: 0.590476\n[66]\tvalid_0's auc: 0.589732\n[67]\tvalid_0's auc: 0.590359\n[68]\tvalid_0's auc: 0.589187\n[69]\tvalid_0's auc: 0.589277\n[70]\tvalid_0's auc: 0.589319\n[71]\tvalid_0's auc: 0.588752\n[72]\tvalid_0's auc: 0.589459\n[73]\tvalid_0's auc: 0.590214\n[74]\tvalid_0's auc: 0.590376\n[75]\tvalid_0's auc: 0.588992\n[76]\tvalid_0's auc: 0.589749\n[77]\tvalid_0's auc: 0.589359\n[78]\tvalid_0's auc: 0.589134\n[79]\tvalid_0's auc: 0.588684\n[80]\tvalid_0's auc: 0.588602\n[81]\tvalid_0's auc: 0.587659\n[82]\tvalid_0's auc: 0.587447\n[83]\tvalid_0's auc: 0.588172\n[84]\tvalid_0's auc: 0.587034\n[85]\tvalid_0's auc: 0.587909\n[86]\tvalid_0's auc: 0.58635\n[87]\tvalid_0's auc: 0.586585\n[88]\tvalid_0's auc: 0.586155\n[89]\tvalid_0's auc: 0.585395\n[90]\tvalid_0's auc: 0.585297\n[91]\tvalid_0's auc: 0.585957\n[92]\tvalid_0's auc: 0.587543\n[93]\tvalid_0's auc: 0.587851\n[94]\tvalid_0's auc: 0.587871\n[95]\tvalid_0's auc: 0.587416\n[96]\tvalid_0's auc: 0.587433\n[97]\tvalid_0's auc: 0.588808\n[98]\tvalid_0's auc: 0.588273\n[99]\tvalid_0's auc: 0.588855\n[100]\tvalid_0's auc: 0.589163\n[1]\tvalid_0's auc: 0.565039\n[2]\tvalid_0's auc: 0.586575\n[3]\tvalid_0's auc: 0.599714\n[4]\tvalid_0's auc: 0.596142\n[5]\tvalid_0's auc: 0.595508\n[6]\tvalid_0's auc: 0.592075\n[7]\tvalid_0's auc: 0.595372\n[8]\tvalid_0's auc: 0.587538\n[9]\tvalid_0's auc: 0.590263\n[10]\tvalid_0's auc: 0.587744\n[11]\tvalid_0's auc: 0.589914\n[12]\tvalid_0's auc: 0.594687\n[13]\tvalid_0's auc: 0.594147\n[14]\tvalid_0's auc: 0.599946\n[15]\tvalid_0's auc: 0.601662\n[16]\tvalid_0's auc: 0.59852\n[17]\tvalid_0's auc: 0.59791\n[18]\tvalid_0's auc: 0.602553\n[19]\tvalid_0's auc: 0.603687\n[20]\tvalid_0's auc: 0.605468\n[21]\tvalid_0's auc: 0.605448\n[22]\tvalid_0's auc: 0.605824\n[23]\tvalid_0's auc: 0.609331\n[24]\tvalid_0's auc: 0.609116\n[25]\tvalid_0's auc: 0.610191\n[26]\tvalid_0's auc: 0.610136\n[27]\tvalid_0's auc: 0.611797\n[28]\tvalid_0's auc: 0.612049\n[29]\tvalid_0's auc: 0.612124\n[30]\tvalid_0's auc: 0.611804\n[31]\tvalid_0's auc: 0.612886\n[32]\tvalid_0's auc: 0.612491\n[33]\tvalid_0's auc: 0.61394\n[34]\tvalid_0's auc: 0.614129\n[35]\tvalid_0's auc: 0.615005\n[36]\tvalid_0's auc: 0.612876\n[37]\tvalid_0's auc: 0.611481\n[38]\tvalid_0's auc: 0.610958\n[39]\tvalid_0's auc: 0.610586\n[40]\tvalid_0's auc: 0.609534\n[41]\tvalid_0's auc: 0.609126\n[42]\tvalid_0's auc: 0.607563\n[43]\tvalid_0's auc: 0.60998\n[44]\tvalid_0's auc: 0.61109\n[45]\tvalid_0's auc: 0.611844\n[46]\tvalid_0's auc: 0.611437\n[47]\tvalid_0's auc: 0.611206\n[48]\tvalid_0's auc: 0.610873\n[49]\tvalid_0's auc: 0.611763\n[50]\tvalid_0's auc: 0.613257\n[51]\tvalid_0's auc: 0.612551\n[52]\tvalid_0's auc: 0.611963\n[53]\tvalid_0's auc: 0.611081\n[54]\tvalid_0's auc: 0.612513\n[55]\tvalid_0's auc: 0.612371\n[56]\tvalid_0's auc: 0.612111\n[57]\tvalid_0's auc: 0.612728\n[58]\tvalid_0's auc: 0.610788\n[59]\tvalid_0's auc: 0.610313\n[60]\tvalid_0's auc: 0.612261\n[61]\tvalid_0's auc: 0.612634\n[62]\tvalid_0's auc: 0.611689\n[63]\tvalid_0's auc: 0.612014\n[64]\tvalid_0's auc: 0.610911\n[65]\tvalid_0's auc: 0.611398\n[66]\tvalid_0's auc: 0.611626\n[67]\tvalid_0's auc: 0.611721\n[68]\tvalid_0's auc: 0.611328\n[69]\tvalid_0's auc: 0.611926\n[70]\tvalid_0's auc: 0.611961\n[71]\tvalid_0's auc: 0.611848\n[72]\tvalid_0's auc: 0.613177\n[73]\tvalid_0's auc: 0.613552\n[74]\tvalid_0's auc: 0.612722\n[75]\tvalid_0's auc: 0.613739\n[76]\tvalid_0's auc: 0.613705\n[77]\tvalid_0's auc: 0.613158\n[78]\tvalid_0's auc: 0.613241\n[79]\tvalid_0's auc: 0.613261\n[80]\tvalid_0's auc: 0.612466\n[81]\tvalid_0's auc: 0.611773\n[82]\tvalid_0's auc: 0.611341\n[83]\tvalid_0's auc: 0.612258\n[84]\tvalid_0's auc: 0.612126\n[85]\tvalid_0's auc: 0.612687\n[86]\tvalid_0's auc: 0.614174\n[87]\tvalid_0's auc: 0.614692\n[88]\tvalid_0's auc: 0.614119\n[89]\tvalid_0's auc: 0.615304\n[90]\tvalid_0's auc: 0.615441\n[91]\tvalid_0's auc: 0.61566\n[92]\tvalid_0's auc: 0.61555\n[93]\tvalid_0's auc: 0.61544\n[94]\tvalid_0's auc: 0.615134\n[95]\tvalid_0's auc: 0.614627\n[96]\tvalid_0's auc: 0.614492\n[97]\tvalid_0's auc: 0.615119\n[98]\tvalid_0's auc: 0.614644\n[99]\tvalid_0's auc: 0.614479\n[100]\tvalid_0's auc: 0.615181\n"
    }
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "source": [
    "importance.mean(axis=1).sort_values(ascending=False).head(20)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Assessment                  858.139293\ncount_correct_attempts      589.396695\nratio_Assessment            566.918432\nduration_std                565.764501\n2010                        389.923489\nacc_0                       290.556852\nmean_coordinates_x          288.921900\ncount_uncorrect_attempts    281.240407\nstd_coordinates_x           258.746443\nstd_coordinates_y           240.005289\nratio_event_code_4000       223.524323\nduration_mean               222.061683\nratio_event_code_3000       207.564758\nratio_Clip                  201.282815\nfrequency                   200.469653\nmean_size                   199.890797\ngood_comment_ratio          195.405997\nmonth_10                    190.501958\nmean_coordinates_y          181.264334\ntotal_duration              180.878907\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}